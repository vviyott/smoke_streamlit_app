# components/tab_ai_news.py
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import streamlit as st
import chromadb
from openai import OpenAI
import os

# API í‚¤ ì„¤ì •
def get_api_key(key_name):
    """Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    try:
        return st.secrets[key_name]
    except:
        return os.getenv(key_name)

# API í‚¤ ì´ˆê¸°í™”
OPENAI_API_KEY = get_api_key('OPENAI_API_KEY')
PINECONE_API_KEY = get_api_key('PINECONE_API_KEY')

## --- ìœ í‹¸ í•¨ìˆ˜ ---
@st.cache_resource
def init_chroma_client():
    """ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    return chromadb.PersistentClient(path="data/chroma_db")

@st.cache_data(ttl=300)
def get_available_collections():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    try:
        client = init_chroma_client()
        return [col.name for col in client.list_collections()]
    except Exception as e:
        st.error(f"ì»¬ë ‰ì…˜ ëª©ë¡ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

def get_collection(collection_name):
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°"""
    if not collection_name:
        return None
    try:
        client = init_chroma_client()
        collection = client.get_collection(name=collection_name)
        return collection
    except Exception as e:
        st.error(f"ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return None

def search_vector_db(collection, query, n_results=20):
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ í•¨ìˆ˜"""
    try:
        if not collection:
            return [{"content": "ì»¬ë ‰ì…˜ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì»¬ë ‰ì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", "title": "ì˜¤ë¥˜", "metadata": {}}]
       
        results = collection.query(
            query_texts=[query],
            n_results=n_results
        )
       
        documents = []
        for i in range(len(results['documents'][0])):
            document = {
                "content": results['documents'][0][i],
                "title": results['metadatas'][0][i].get('title', 'ì œëª© ì—†ìŒ'),
                "metadata": results['metadatas'][0][i]
            }
            documents.append(document)
       
        return documents
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return [{"content": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", "title": "ì˜¤ë¥˜", "metadata": {}}]

def get_gpt_response(query, search_results, api_key, model="gpt-4o-mini"):
    """OpenAIë¥¼ í™œìš©í•œ ì‘ë‹µ ìƒì„± í•¨ìˆ˜"""
    if not api_key:
        return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    try:
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        api_key = api_key.replace('\ufeff', '')
        client = OpenAI(api_key=api_key)
       
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ë¬¸ì„œ ë²ˆí˜¸ ì œê±°)
        context = "ë‹¤ìŒì€ ì¤‘ì•™ì¼ë³´ì—ì„œ ìˆ˜ì§‘í•œ ë‹´ë°° ê´€ë ¨ ë°ì´í„°ì…ë‹ˆë‹¤:\n\n"
       
        for i, result in enumerate(search_results):
            context += f"ê¸°ì‚¬ ì œëª©: {result['title']}\n"
           
            # ë©”íƒ€ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì •ë³´ë§Œ ì„ ë³„ì ìœ¼ë¡œ ì¶”ê°€
            if result['metadata']:
                metadata = result['metadata']
                # ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œ ë©”íƒ€ë°ì´í„°ë§Œ í¬í•¨
                if 'published_date' in metadata and metadata['published_date']:
                    context += f"ì‘ì„±ì¼: {metadata['published_date']}\n"
                if 'url' in metadata and metadata['url']:
                    context += f"ì¶œì²˜: {metadata['url']}\n"
                if 'source' in metadata and metadata['source']:
                    context += f"ì–¸ë¡ ì‚¬: {metadata['source']}\n"
                # ë¬¸ì„œ ë²ˆí˜¸ë‚˜ ê¸°íƒ€ ë‚´ë¶€ ë©”íƒ€ë°ì´í„°ëŠ” ì œì™¸
           
            # ë‚´ìš© ìš”ì•½ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„)
            content = result['content']
            if len(content) > 80000:
                content = content[:80000] + "..."
            context += f"ë‚´ìš©: {content}\n\n"

        # ê°œì„ ëœ GPT í”„ë¡¬í”„íŠ¸
        system_prompt = """ë‹¹ì‹ ì€ ë‹´ë°° ë° í¡ì—°ê³¼ ê´€ë ¨ëœ ì •ì±…, ê±´ê°•, ì‚¬íšŒì  ì´ìŠˆ ì „ë°˜ì— ëŒ€í•œ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
        ì œê³µëœ ê¸°ì‚¬ë‚˜ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì ì ˆí•œ ìˆ˜ì¤€ì˜ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

        âš ï¸ **ì§ˆë¬¸ ìœ í˜• íŒë³„ì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤:**
        
        **ê°„ë‹¨í•œ ì§ˆë¬¸ ìœ í˜• (ì°¸ê³  ê¸°ì‚¬ ì ˆëŒ€ í¬í•¨ ê¸ˆì§€):**
        - ì‚¬ì‹¤ í™•ì¸: "ëª‡ ë…„ë„ì¸ê°€ìš”?", "ì˜¬í•´ëŠ” ëª‡ ë…„ì¸ê°€ìš”?"
        - ë‹¨ìˆœ ì •ë³´: "ë‹´ë°° ê°€ê²©ì€?", "í¡ì—°ìœ¨ì€?"
        - íŒ/ì¡°ì–¸ ìš”ì²­: "ê¸ˆì—° íŒì„ ì•Œë ¤ì£¼ì„¸ìš”", "ê¸ˆì—° ë°©ë²•ì€?", "ì–´ë–»ê²Œ ê¸ˆì—°í•˜ë‚˜ìš”?"
        - ì¼ë°˜ì  ì¡°ì–¸: "ê¸ˆì—°ì— ì¢‹ì€ ìŒì‹ì€?", "ê¸ˆì—° í›„ ì£¼ì˜ì‚¬í•­ì€?"
        
        â†’ ì´ëŸ° ì§ˆë¬¸ë“¤ì€ ê°„ê²°í•˜ê³  ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€ (2-5ë¬¸ì¥)
        â†’ ğŸ“° ì°¸ê³  ê¸°ì‚¬ ì„¹ì…˜ì„ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
        
        **ë³µì¡í•œ ì§ˆë¬¸ ìœ í˜• (ì°¸ê³  ê¸°ì‚¬ í¬í•¨ ê°€ëŠ¥):**
        - ì •ì±… ë¶„ì„: "ìµœê·¼ ê¸ˆì—° ì •ì±…ì˜ íš¨ê³¼ëŠ”?", "ì •ì±… ë³€í™” ë‚´ìš©ì€?"
        - í˜„í™© ë¶„ì„: "ì§€ì—­ë³„ í¡ì—°ìœ¨ ë¹„êµ", "ì—°ë„ë³„ ì¶”ì´ ë¶„ì„"
        - ë°ì´í„° ìš”ì²­: "êµ¬ì²´ì ì¸ í†µê³„ë‚˜ ìˆ˜ì¹˜ë¥¼ ë¬»ëŠ” ì§ˆë¬¸"
        - ì‚¬íšŒì  ì˜í–¥: "ê¸ˆì—° ì •ì±…ì´ ì‚¬íšŒì— ë¯¸ì¹œ ì˜í–¥ì€?"
        
        â†’ ì´ëŸ° ì§ˆë¬¸ë“¤ë§Œ ìƒì„¸í•œ ë‹µë³€ + ğŸ“° ì°¸ê³  ê¸°ì‚¬ í¬í•¨
        
        **ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­:**
        - ë‹µë³€ì— "(ë¬¸ì„œ 1)", "(ë¬¸ì„œ 20)", "(ë¬¸ì„œ ë²ˆí˜¸)" ê°™ì€ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
        - "ë¬¸ì„œì— ë”°ë¥´ë©´", "xxë²ˆ ë¬¸ì„œì—ì„œ" ê°™ì€ ë¬¸ì„œ ì°¸ì¡° í‘œí˜„ ê¸ˆì§€
        - ê°„ë‹¨í•œ ì§ˆë¬¸ì— "ğŸ“° ì°¸ê³  ê¸°ì‚¬" ì„¹ì…˜ í¬í•¨ ì ˆëŒ€ ê¸ˆì§€
        - íŒì´ë‚˜ ì¡°ì–¸ì„ ë¬»ëŠ” ì§ˆë¬¸ì—ëŠ” ê¸°ì‚¬ ë§í¬ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
        - ì°¸ê³  ê¸°ì‚¬ì— URLì´ ì—†ëŠ” ê¸°ì‚¬ ì œëª©ë§Œ ë‚˜ì—´í•˜ëŠ” ê²ƒì€ ê¸ˆì§€ (ë°˜ë“œì‹œ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ í˜•íƒœë¡œ ì œê³µ)
        
        **ê¸°íƒ€ ì£¼ì˜ì‚¬í•­:**
        - ì˜¬í•´ëŠ” 2025ë…„ì…ë‹ˆë‹¤
        - ì§ˆë¬¸ ìœ í˜•ì„ ì •í™•íˆ íŒë³„í•˜ì—¬ ì ì ˆí•œ ë‹µë³€ í˜•ì‹ ì„ íƒ
        - ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œë§Œ ë‹µë³€
        """

        user_prompt = f"""{context}

        ì‚¬ìš©ì ì§ˆë¬¸: {query}

        ìœ„ ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

        ğŸ” **ì§ˆë¬¸ ìœ í˜•ì„ ë¨¼ì € íŒë³„í•˜ì„¸ìš”:**

        ë§Œì•½ ì§ˆë¬¸ì´ ë‹¤ìŒê³¼ ê°™ì€ **ê°„ë‹¨í•œ ìœ í˜•**ì´ë¼ë©´:
        - íŒ/ì¡°ì–¸ ìš”ì²­ ("ê¸ˆì—° íŒ", "ê¸ˆì—° ë°©ë²•", "ì–´ë–»ê²Œ ê¸ˆì—°", "ê¸ˆì—°ì— ì¢‹ì€", "ê¸ˆì—° í›„ ì£¼ì˜ì‚¬í•­")
        - ì‚¬ì‹¤ í™•ì¸ ("ëª‡ ë…„ë„", "ì˜¬í•´ëŠ”", "ê°€ê²©ì€")
        - ë‹¨ìˆœ ì •ë³´ ("í¡ì—°ìœ¨", "í†µê³„")
        
        â†’ 2-5ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ë§Œ ì œê³µ
        â†’ ğŸ“° ì°¸ê³  ê¸°ì‚¬ ì„¹ì…˜ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”

        ë§Œì•½ ì§ˆë¬¸ì´ ë‹¤ìŒê³¼ ê°™ì€ **ë³µì¡í•œ ìœ í˜•**ì´ë¼ë©´:
        - ì •ì±… ë¶„ì„ ("ì •ì±… íš¨ê³¼", "ì •ì±… ë³€í™”", "ë²•ì•ˆ ë‚´ìš©")
        - í˜„í™© ë¶„ì„ ("ì§€ì—­ë³„ ë¹„êµ", "ì—°ë„ë³„ ì¶”ì´", "ìƒì„¸í•œ í˜„í™©")
        - ë°ì´í„° ë¶„ì„ ("êµ¬ì²´ì ì¸ í†µê³„", "ìˆ˜ì¹˜ ë¶„ì„", "ì—°êµ¬ ê²°ê³¼")
        
        â†’ ìƒì„¸í•œ ë‹µë³€ + ì‹¤ì œë¡œ ì°¸ì¡°í•œ ê¸°ì‚¬ë§Œ ğŸ“° ì°¸ê³  ê¸°ì‚¬ ì„¹ì…˜ì— í¬í•¨
        â†’ ì°¸ê³  ê¸°ì‚¬ í˜•ì‹: "- [ê¸°ì‚¬ ì œëª©](URL ë§í¬)" í˜•íƒœë¡œ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ ì œê³µ

        âš ï¸ **ë§¤ìš° ì¤‘ìš”:**
        1. íŒ/ì¡°ì–¸/ë°©ë²•ì„ ë¬»ëŠ” ì§ˆë¬¸ì—ëŠ” ê¸°ì‚¬ ë§í¬ë¥¼ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
        2. "(ë¬¸ì„œ ë²ˆí˜¸)" ê°™ì€ í‘œí˜„ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
        3. ì§ˆë¬¸ ìœ í˜•ì„ ì •í™•íˆ íŒë³„í•˜ì—¬ ì ì ˆí•œ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
        4. ë³µì¡í•œ ì§ˆë¬¸ì˜ ê²½ìš° ì°¸ê³  ê¸°ì‚¬ëŠ” ë°˜ë“œì‹œ "[ì œëª©](URL)" í˜•íƒœì˜ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ë¡œ ì œê³µí•˜ì„¸ìš”
        5. URLì´ ì—†ëŠ” ê¸°ì‚¬ëŠ” ì°¸ê³  ê¸°ì‚¬ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
        """

        # API í˜¸ì¶œ
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,  # ë” ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ ë‚®ì¶¤
            max_tokens=1500    # ë” ê¸´ ë‹µë³€ì„ ìœ„í•´ ëŠ˜ë¦¼
        )
       
        return response.choices[0].message.content
       
    except Exception as e:
        error_msg = str(e)
        if "auth" in error_msg.lower() or "api key" in error_msg.lower():
            return "OpenAI API í‚¤ ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        else:
            return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}"

def get_simple_response(query, search_results):
    """API í‚¤ê°€ ì—†ì„ ë•Œ ê°„ë‹¨í•œ ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    if not search_results or search_results[0].get("title") == "ì˜¤ë¥˜":
        return "ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
   
    result_text = f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼:\n\n"
   
    for i, result in enumerate(search_results[:5]):
        result_text += f"**ë¬¸ì„œ {i+1}:** {result['title']}\n"
       
        # ë‚ ì§œ ì •ë³´ ì¶”ê°€
        if 'published_date' in result['metadata']:
            result_text += f"**ë‚ ì§œ:** {result['metadata']['published_date']}\n"
       
        # ë‚´ìš© ìš”ì•½ (150ìë¡œ ì œí•œ)
        content = result['content']
        if len(content) > 150:
            content = content[:150] + "..."
        result_text += f"{content}\n\n"
   
    result_text += "ë” ìì„¸í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    return result_text

def chat_response(question, collection):
    """ì±—ë´‡ ì‘ë‹µ ìƒì„± í•¨ìˆ˜"""
    # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
    search_results = search_vector_db(collection, question)
   
    # ChatGPT API í‚¤ê°€ ìˆìœ¼ë©´ GPT ì‚¬ìš©, ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ì‘ë‹µ
    if OPENAI_API_KEY:
        return get_gpt_response(question, search_results, OPENAI_API_KEY)
    else:
        return get_simple_response(question, search_results)

def news_chatbot():
    """ë‹´ë°° ê´€ë ¨ ë‰´ìŠ¤ ì±—ë´‡ ë©”ì¸ í•¨ìˆ˜"""
    st.markdown("## ë‹´ë°°ê¸°ì‚¬ ë°ì´í„° AI ë¶„ì„ê°€ âœ¨")
    st.markdown("""
    ë‹´ë°°ì™€ ê´€ë ¨ëœ ìµœê·¼ ë‰´ìŠ¤, ì •ì±…, í¡ì—° ë¶€ìŠ¤, ê±´ê°• ë¬¸ì œ ë“± ê¶ê¸ˆí•œ ì ì„ ììœ ë¡­ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.  
    AIê°€ ì¤‘ì•™ì¼ë³´ ê¸°ì‚¬ ê¸°ë°˜ ë°ì´í„°ì—ì„œ ìœ ì˜ë¯¸í•œ ì •ë³´ë¥¼ ë¶„ì„í•´ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.
    """)


    # ì»¬ë ‰ì…˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    collection_list = get_available_collections()
    if not collection_list:
        st.warning("ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì²« ë²ˆì§¸ ì»¬ë ‰ì…˜ ìë™ ì„ íƒ (ë‹¤ë¥¸ íƒ­ë“¤ê³¼ ì¼ê´€ì„± ìœ ì§€)
    collection_name = collection_list[0]
    
    # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
    collection = get_collection(collection_name)

    # ì»¬ë ‰ì…˜ ì •ë³´ í‘œì‹œ
    if collection:
        try:
            count = collection.count()
            st.success(f"ì»¬ë ‰ì…˜ '{collection_name}'ì—ì„œ {count:,}ê°œì˜ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
    else:
        st.warning("ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ê±°ë‚˜ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì»¬ë ‰ì…˜ ëª©ë¡ì„ í™•ì¸í•˜ì„¸ìš”.")
        return

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "is_processing" not in st.session_state:
        st.session_state.is_processing = False

    # ì˜ˆì‹œ ì§ˆë¬¸ ì„¹ì…˜
    st.markdown(
        "<p style='font-size:20px; font-weight:600;'>ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸</p>", 
        unsafe_allow_html=True
    )
    example_questions = [
        "ê°€ì¥ ìµœê·¼ì— ë°œí‘œëœ ê¸ˆì—° ì •ì±…ì—ëŠ” ì–´ë–¤ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆë‚˜ìš”?",
        "í¡ì—° ë¶€ìŠ¤ ì„¤ì¹˜ê°€ ë¯¼ì› ê°ì†Œì— íš¨ê³¼ê°€ ìˆì—ˆë‚˜ìš”?",
        "ë‹´ë°°ì™€ ê´€ë ¨ëœ ê±´ê°• í”¼í•´ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?",
        "ê¸ˆì—° íŒì„ ì•Œë ¤ì£¼ì„¸ìš”!"
    ]

    # ì˜ˆì‹œ ì§ˆë¬¸ì„ 4ì—´ë¡œ ë°°ì¹˜ (ì²˜ë¦¬ ì¤‘ì¼ ë•ŒëŠ” ë¹„í™œì„±í™”)
    cols = st.columns(4)
    for i, question in enumerate(example_questions):
        with cols[i % 4]:
            if st.button(question, key=f"example_{i}", use_container_width=True, disabled=st.session_state.is_processing):
                st.session_state.selected_question = question
                st.session_state.is_processing = True

    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼ (ì²˜ë¦¬ ì¤‘ì¼ ë•ŒëŠ” ë¹„í™œì„±í™”)
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”", disabled=st.session_state.is_processing):
        st.session_state.chat_history = []
        st.session_state.is_processing = False
        st.rerun()

    st.divider()

    # ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ í´ë¦­ ì‹œ ì²˜ë¦¬ (ì±„íŒ…ì°½ë³´ë‹¤ ë¨¼ì € í™•ì¸)
    if "selected_question" in st.session_state:
        selected_input = st.session_state.selected_question
        del st.session_state.selected_question
    else:
        selected_input = None

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ (ì²˜ë¦¬ ì¤‘ì¼ ë•ŒëŠ” ì±„íŒ…ì°½ ìˆ¨ê¹€)
    chat_input = None
    if not st.session_state.is_processing:
        chat_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì„œìš¸ì—ì„œ í¡ì—° êµ¬ì—­ì´ ê°€ì¥ ë§ì€ ìì¹˜êµ¬ëŠ” ì–´ë””ì¸ê°€ìš”?)")
        if chat_input:
            st.session_state.is_processing = True
    
    # ìµœì¢… ì…ë ¥ ê²°ì • (ì˜ˆì‹œ ì§ˆë¬¸ ìš°ì„ , ê·¸ ë‹¤ìŒ ì±„íŒ… ì…ë ¥)
    final_input = selected_input if selected_input else chat_input

    if final_input:
        # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
        if not collection:
            with st.chat_message("assistant"):
                st.markdown("âš ï¸ ì»¬ë ‰ì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”. í˜„ì¬ ì»¬ë ‰ì…˜ì´ ì„ íƒë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.session_state.chat_history.append({
                "role": "assistant", 
                "content": "âš ï¸ ì»¬ë ‰ì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”. í˜„ì¬ ì»¬ë ‰ì…˜ì´ ì„ íƒë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            })
            st.session_state.is_processing = False
        else:
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
            with st.chat_message("user"):
                st.markdown(final_input)

            # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ì´ë ¥ì— ì €ì¥
            st.session_state.chat_history.append({"role": "user", "content": final_input})

            # ì‘ë‹µ ìƒì„±  
            with st.spinner("ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆëŠ” ì¤‘..."):
                response = chat_response(final_input, collection)

            # ì‘ë‹µ ë©”ì‹œì§€ í‘œì‹œ
            with st.chat_message("assistant"):
                st.markdown(response)

            # AI ì‘ë‹µì„ ëŒ€í™” ì´ë ¥ì— ì €ì¥
            st.session_state.chat_history.append({"role": "assistant", "content": response})
            
            # ì²˜ë¦¬ ì™„ë£Œ í›„ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.is_processing = False

        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()
    
    # ì²˜ë¦¬ ì¤‘ì¼ ë•Œ ìƒíƒœ í‘œì‹œ
    if st.session_state.is_processing and not final_input:
        st.info("ğŸ’­ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
